---
title: Zero shot classification - first exploration
author: Sjoerd de Haan
date: 14-01-2024
jupyter: urban-sounds
execute: 
  cache: true
---

Here I try a zero-shot classification model to classify urban sounds.

Results

- Many of the used samples contain background sound only
- The CLAP model does not perform well on this dataset  



## Load dataset
We use the `audiofolder` dataset from the `huggingface/datasets` library to load the samples.

```{python}
#| label: "Wav samples"
from pathlib import Path
import sys
sys.path.append("../..")
from config import SAMPLES_DIR

datadir = Path(SAMPLES_DIR)
samples = list(datadir.glob("*.wav"))
samples[:3]
```


We are loading audio files from a folder with the `AudioFolder` dataset builder.
the wav audio is decoded with the `soundfile` module and stored as numpy arryas. 

```{python}
#| label: hugging-face-datasets
from datasets import load_dataset
dataset = load_dataset("audiofolder", data_dir=datadir)
dataset
```

Let's check the first sample in the dataset

```{python}
#| label: "First sample"
dataset['train'][0]
dataset['train'][0]['audio']
```

## Audio samples
Here are some sample audio files:
```{python}
#| label: "Audio samples"
from IPython.display import Audio
from IPython.display import display

for i, sample in zip(range(10), dataset['train']):
  print(sample['audio']['path'].split('/')[-1])
  display(Audio(filename=sample['audio']['path']))
```

These 10 samples are all background noise.

## Zero shot classification

I use the `zero-shot-audio-classification` pipeline from the `transformers` library to classify the audio samples with CLAP.


```{python}
#| label:  constants
from config import DEVICE, MODELS, URBAN_SOUNDS_LABELS

MODEL = MODELS['clap_music_speech']
MODEL_LARGE = MODELS['clap_general']
LABEL_DICT = URBAN_SOUNDS_LABELS
LABELS = list(URBAN_SOUNDS_LABELS.values()) + ['Silence', 'Background noise']
```


```{python}
#| label: pipeline
from transformers import pipeline
audio_classifier = pipeline(
  task = "zero-shot-audio-classification",
  model = MODEL, 
  num_workers =1,
  device=DEVICE,
  batch_size = 2,
  candidate_labels = LABELS, 
)
```

Predict for all samples in the dataset

```{python}
#| label: predict
#%%timeit
audio = [sample['audio']['array'] for sample in dataset['train']]
%time results = audio_classifier(audio)
```


## Confident predictions
We check the most confident prediction for each class. 


```{python}
#| label: fig-predict-dataframe
#| fig-cap: "Most confident predictions per class"
import pandas as pd
pd.set_option('display.precision', 3)
pd.set_option('display.float_format', lambda x: '%.3f' % x)
r = results[0]

def scores_to_df(results):
  flat = [{line['label']: line['score'] for line in r} for r in results]
  scores = pd.DataFrame(flat)
  return(scores)

scores = scores_to_df(results)
max_scores = scores.max()
max_scores.plot(kind='bar')
#[item['path'].split('/')[-1] for item in dataset['train']['audio']]
```


Get the most confident prediction per class
```{python}
#| label: show-confident-predicitons
comments = {
  'Claxon': 'bycicle bell, metal sound',
  'Silence': 'silence engine',
  'Motorcycle': 'airplane',
  'Music': 'low feq background sounds',
  'Moped alarm': 'bird singing and bicycle bell',
  'Background noise': 'low freq noise and airplane',
  'Slamming door': 'metal construction sounds',
  'Moped': 'starting engine and bird',
  'Gunshot': 'metal sounds and something falling',
  'Talking': 'crumbling sound',
  'Screaming': 'screaming',
}
for label, i in scores.idxmax().items():
    fname = dataset['train'][i]['audio']['path']
    s = scores.iloc[i]
    s = s.sort_values(ascending=False)
    assigned = s.idxmax()
    print(fname.split("/")[-1])
    print("predicted label:", assigned)
    print("i hear:", comments[label])
    print("Recieved highest score in category: ", label)
    display(Audio(filename=fname))
    display(s)
    print("-----------------------------------")
```

Only a few samples received a correct label. 

### Check index

Perhaps I shuffled the files along the way.
Let me make the predictions again to check if I have shuffled the samples.  

```{python}
#| label: "Check index"
max_idx = scores.idxmax()
max_subset = dataset['train'][max_idx]
max_preds = list(audio_classifier(s['array'] for s in max_subset['audio']))
max_preds = scores_to_df(max_preds)
max_preds.index = max_idx.index
max_preds
```





## Clean up the dataset
Some `wav` files could not be loaded. I removed those. 


```{python}
def validate_dataset(dataset, max_samples=10):
  """Validate a few samples from the dataset"""
  errors = {}
  for i, sample in enumerate(dataset['train']):
    if i >= max_samples:
      break
    print(f"Processing sample {i}: {sample['audio']['path']}")
    try:
      pred = audio_classifier(sample['audio']['array'], candidate_labels=LABELS)
      print(f"Prediction: {pred[0]['label']} ({pred[0]['score']:.3f})")
    except Exception as e:
      errors[sample['audio']['path']] = str(e)
      print(f"Error: {e}")
  
  print(f"\nValidation complete. Found {len(errors)} errors out of {min(max_samples, len(dataset['train']))} samples.")
  return errors

# Run validation
# errors = validate_dataset(dataset)
```

